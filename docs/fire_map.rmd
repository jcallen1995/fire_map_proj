---
title: "California Fire Map"
author: "[Jason Allen](https://jcallen1995.github.io/)"
subtitle: "Years 20XX-20XX"
output:
  html_document:
    code_folding: 'hide'
    theme: journal

---

So, to start out I need to get some data. I'm thinking of taking; 
 - California Counties data (X)
  * US boundaries data package has it.
 - average rainfall (X)
  * got it from national weather sevice.
 - county population(X)
  * got it from census
 - fire polygons or rasters (X)
  * I found exactly what I wanted.
 - city names (X)
  * I ended up getting this from another source.
 - city polygons (X)
  * Got it from the city names source.
 
and basically combining all of these into an interractive map that
the user can zoom in using the leaflet package, flip through the 
years and also see a graph showing the estimated number of people
whose lives were affected by the fires. I could also add other fitting
data if I find good sources, but realistically, I might struggle to
even find the data that I have listed here.

Tomorrow I'll get started tracking down the data. 

```{r}
library(tidyverse)
library(raster)
library(sf)
library(rgdal)

GDALinfo("../data/nws_precip_ytd_20220101_conus.tif")

precipitation_conus_path <- "../data/nws_precip_ytd_20220101_conus.tif"

precip_conus_test <- raster(precipitation_conus_path, band = 2)

spplot(precip_conus_test)

```

Okay, so I've tentatively got my precipitation data, wait, let's check that.

Here's the precipitation data source

https://water.weather.gov/precip/download.php

Source: https://www.noaa.gov/

GeoTIFF

The new QPE GeoTIFFs generated from the NCEP Stage IV data are multi-band GeoTIFF. The bands they contain are:

    Band 1 - Observation - Last 24 hours of QPE spanning 12Z to 12Z in inches
    Band 2 - PRISM normals - PRISM normals in inches (see "Normal Precipitation" section on the About page)
    Band 3 - Departure from normal - The departure from normal in inches
    Band 4 - Percent of normal - The percent of normal

Now, this raster shows precip in inches of rainfall. I'm not going to be using
this for a quantitative calculation, so simply having this much is enough for me.

The next step will be downloading all of the yearly data rasters from 2016-2022,
then, once I actually have all of them, I have to figure out how to isolate the
California part of the data. Most likely, I will be projecting the state boundary
onto the raster and then selecting the raster points within the polygon. Should
be simple enough once I actually get around to it. I need to also find the rest
of my data.

The data protocol changed in 2017 for the precip data, so I might need to do something
different for year 2016 precip data.

Now to check on the r package data sources.

```{r}
library(USAboundaries)

california_state_select <- us_boundaries(states = 'california')

cali_counties_data <- us_boundaries(states = 'california', type = "county")

plot(california_state_select)
plot(cali_counties_data)
```

Okay, so I've got the cali state and county polys in this package. Next is to check
on the uscities.csv, and find out where its data comes from as well as the 
us boundary data comes from.

Actually, there is no data source imbeded in the csv that I can find so I'm gonna
try some open source data.

https://data.ca.gov/dataset/ca-geographic-boundaries

Source: https://data.ca.gov/

this is the one I'll try

```{r}
library(sf)

ca_places_path <- "../data/ca-places-boundaries/CA_Places_TIGER2016.shp"

ca_places_bound_test <- st_read(ca_places_path) %>% 
  st_as_sf() %>% 
  filter(NAME == "Santa Rosa")

plot(ca_places_bound_test)
```

Okay, this looks promising. I'm just not 100% sure if it will give me city
polygons or what it even is really. It actually looks like exactly what I wanted.


Now onto fire data for california. I'll try this dataset first.

https://hub-calfire-forestry.hub.arcgis.com/datasets/CALFIRE-Forestry::fire-perimeters/explore?location=37.417017%2C-122.003310%2C10.00

Source: https://www.fire.ca.gov/


Seems promising. Time to start unpacking the data.

```{r}

fire_data_path <- "../data/California_Wildland_Fire_Perimeters_-All/California_Wildland_Fire_Perimeters_All.shp"

fire_data_perim_test <- st_read(fire_data_path) %>% 
  st_as_sf() %>% 
  filter(FIRE_NAME == "TUBBS")

print(fire_data_perim_test)

plot(fire_data_perim_test)

```

Okay, that was great. Now I need to get the populations of each county. I found
a data source here. It's xslx format, but that should be fine.

https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html

Source: https://www.census.gov/en.html


```{r}

library(readxl)

county_pop_path <- "../data/co-est2019-annres-06.xlsx"

county_pop <- read_excel(county_pop_path)

```


Okay, looks good mostly. The csv doesn't have good column names, but that's fine.
They're still labeled, just not conveniently so I can work with it. So, these
numbers are the estimates from between 2010 and 2019 which is basically just a
rough estimation which is close enough for me. These estimates are more than good
enough for what I intend to use them for.


OKAY. So I now have all my data. What is the next step? I should get started with
making one of these data sets my 'base' and adding the data layers on from there.
What is my core data layer? ...

It's probably best to start with the US boundaries data set. It will give me the
state and county polygons. I also need to figure out what data is getting joined
to what. So, there are going to be a few separate layers. The base layer will be
the leaflet map that I'm projecting the data onto. Just above the base layer 
should be the precipitation layer so as to keep the polygon layer boundaries more
clearly defined. The layer above that will be the county layer which will have 
the county population data joined to it. Then, the next layer up will be the city
polygon layer and the fire boundary layer on top. These two layers will help
illustrate the proximity of the fires to major city centers.

- leaflet map                         
- precipitation raster                
- county poly with joined pop data    Tidy:[X]
- city polygons                       Tidy:[X]
- fire boundary poly                  Tidy:[X]

- affected pop per year graph

With the map breakdown like this, I can create the graph of population 'affected'
by fires relatively easily.

So in order to get everything ready for the map, I need to start cleaning up the
data and joining what needs to be joined. To do this, I should make a ggplot that
allows me to visualize the data layers from bottom to top and make sure I'm cutting
out any data entries or columns that I don't need.


Let's get started with the us boundaries ggplot

```{r}

#libraries are already called, but I might need to reimport the bounradies

#get the california state boundary
california_state <- us_boundaries(states = 'california')

#get the california counties as an sfc
cali_counties <- us_boundaries(states = 'california', type = "county")

# I didn't need to recall the boundaries, but I'll just leave them here for now.

#okay, now I want to join the population data to cali_counties.
#we want a left join where pop gets added onto the states based on name.
print(county_pop)
print(cali_counties$name)
#so, it appears that the names don't match. Trying to remove the .~~~ County, California
#could be annoying, so I might just add that onto the cali_counties name and join by that
#I can try mutating on a new column with altered nameing.
cali_counties_join <- cali_counties %>% 
  mutate(name_join = paste( ".", cali_counties$name, " County, California", sep = ""))

print(cali_counties_join)

#now try a left join, horrific column name
cali_counties_join <- cali_counties_join %>% 
  left_join(county_pop, by = c("name_join" = "table with row headers in column A and column headers in rows 3 through 4 (leading dots indicate sub-parts)"))

#great, that actually worked, now we can cut cali_counties down to size with select and filter.
#XXXXXXXXXX Continue from here XXXXXXXXXX
cali_counties_final <- cali_counties_join %>% 
  st_as_sf(crs = 4326) %>% 
  dplyr::select(name, '...2', geometry) %>%  #I seriously have to specify this? Completely ridiculous
  rename("county_population" = "...2") %>% 
  rename("county_name" = "name")

#create ggplot
ggplot()+
  #color the cali counties and their borders
  geom_sf(data = cali_counties_final, fill = "#454742", col = "#8d8c8b", size = .5)+
  #create the theme for the background. I'm reusing an old theme
  theme(panel.background = element_rect(fill = "#272727",
                                        colour = "#272727",
                                        size = .5,
                                        linetype = "dashed"),
        panel.grid.major = element_line(size = .5,
                                        color = "#3d3d3d",
                                        linetype = "solid"))+
  #title and subtitle. I might need another legend position for credits.
  theme(legend.position = "hide")+
    labs(title = "TITLE",
         subtitle = "SUBTITLE",
         x = "",
         y ="")


```

Okay, I managed to solve the github push issue by creating a new repo and making
sure to .gitignore the data folder. Now I have a tidy looking county pop poly 
var. 

Now I need to decide what to do next. I feel like I want to set up the leaflet
now since the rest of the data just needs to be wrangled. Then again, getting the
data tidy first would probably be for the best. Okay, I'll focus on keeping the 
data tidy first and not get distracted.

```{r}
#time to tidy the city polys
ca_places_path <- "../data/ca-places-boundaries/CA_Places_TIGER2016.shp"

ca_places_bound <- st_read(ca_places_path) %>% 
  st_as_sf(crs = 4326) %>% 
  dplyr::select(NAMELSAD, geometry) %>% 
  st_simplify(dTolerance = 200) #freeport ends up with 'polygon empty' keep note in case it becomes a problem later

#create ggplot
ggplot()+
  #color the objects
  geom_sf(data = ca_places_bound, fill = "#454742", col = "#8d8c8b", size = .5)+
  #create the theme for the background. I'm reusing an old theme
  theme(panel.background = element_rect(fill = "#272727",
                                        colour = "#272727",
                                        size = .5,
                                        linetype = "dashed"),
        panel.grid.major = element_line(size = .5,
                                        color = "#3d3d3d",
                                        linetype = "solid"))+
  #title and subtitle. I might need another legend position for credits.
  theme(legend.position = "hide")+
    labs(title = "TITLE",
         subtitle = "SUBTITLE",
         x = "",
         y ="")
```


Good, the next step should be to tidy up the fire map data and split it into 
different years. There's probably a built in way of dealing with that, perhaps 
with groups or something, but I'm going to split the data for the readability of
my code for now. I can pack things up nicer on the final map if I want to.


```{r}
#fire map time
fire_data_path <- "../data/California_Wildland_Fire_Perimeters_-All/California_Wildland_Fire_Perimeters_All.shp"

#fire data has date format for dates
fire_data_perim <- st_read(fire_data_path) %>% 
  st_as_sf() %>% 
  #okay, so I' having issues with small polygons in the multipoly
  #I'll try unioning them
  dplyr::select(YEAR_, FIRE_NAME, geometry) %>% 
  filter(YEAR_ > 2015)
  

#now select for fires in 2016
fire_data_2016 <- fire_data_perim %>% 
  filter(YEAR_ == 2016) %>% 
  st_union() %>% #this eliminates the issue st_simplify was having with tiny polygons
  st_simplify(dTolerance = 200)

#the fire data is already in wgs 84, so no worries there

#create ggplot
ggplot()+
  #color the objects
  geom_sf(data = fire_data_2016, fill = "#454742", col = "#8d8c8b", size = .5)+
  #create the theme for the background. I'm reusing an old theme
  theme(panel.background = element_rect(fill = "#272727",
                                        colour = "#272727",
                                        size = .5,
                                        linetype = "dashed"),
        panel.grid.major = element_line(size = .5,
                                        color = "#3d3d3d",
                                        linetype = "solid"))+
  #title and subtitle. I might need another legend position for credits.
  theme(legend.position = "hide")+
    labs(title = "TITLE",
         subtitle = "SUBTITLE",
         x = "",
         y ="")

```


Now that the fire data is tidy and ready for the map, I'll tidy up the precip data


```{r}
#do I need raster libraries
library(raster)
library(rasterVis)
library(ggplot2)

#first get the us boundary CA state poly
ca_state_poly <- us_boundaries(states = "California")


#now get the precip data
GDALinfo("../data/nws_precip_ytd_20220101_conus.tif")
precipitation_conus_path <- "../data/nws_precip_ytd_20220101_conus.tif"

#create the raster
precip_conus <- raster(precipitation_conus_path, band = 2) %>% 
  projectRaster(crs = 4326) %>% 
  #crop california data
  #crop(ca_state_poly) %>% 
  #select only cali borders
  raster::intersect(ca_state_poly) %>% 
  #mask the state polygon
  raster::mask(ca_state_poly) %>% 
  #convert to pts
  rasterToPoints(spatial = TRUE) %>% 
  #then to df
  data.frame()
  

#plot(precip_conus)


ggplot()+
  #color the objects
  geom_sf(data = ca_state_poly, fill = "#454742", col = "#8d8c8b", size = .5)+
  #create the theme for the background. I'm reusing an old theme
  theme(panel.background = element_rect(fill = "#272727",
                                        colour = "#272727",
                                        size = .5,
                                        linetype = "dashed"),
        panel.grid.major = element_line(size = .5,
                                        color = "#3d3d3d",
                                        linetype = "solid"))+
  #title and subtitle. I might need another legend position for credits.
  geom_raster(data = precip_conus, aes(x=x, y=y, fill = nws_precip_ytd_20220101_conus))+
  scale_fill_gradientn(colors = c("#fff8bf", "#6e6a4b",  "#141b57", "#000724"))+
  theme(legend.position = "hide")+
    labs(title = "TITLE",
         subtitle = "SUBTITLE",
         x = "",
         y ="")

```

FINALLY!!!! I had to use the raster::mask fuction to do what I wanted cause
raster::intersect only selected by the extent, either way, I have the tidy raster
data I was looking for. The next step should be setting up the leaflet map. I
think the best way to go about this will be to create the leaflet map I want in
this RMD, but then create a new RMD that will be cleaner and just show the 
leaflet map and have this rmd in a different folder showing my process.











